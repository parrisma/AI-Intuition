{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../assets/images/construction.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Journey 4\n",
    "## Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Apple CNN](./images/AppleCNN-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isdir, isfile, join\n",
    "import re\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/fruits-360-data/fruits-360'\n",
    "TEST_DATA = DATA_DIR + '/Test'\n",
    "TRAIN_DATA = DATA_DIR + '/Training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create a one-hot encoding for the given list\n",
    "#\n",
    "def create_one_hot_encoding_dicts(list_to_encode):\n",
    "    list_to_one_hot = dict()\n",
    "    one_hot_to_item = dict()\n",
    "    for i, l in enumerate(list_to_encode):\n",
    "        oh = np.zeros((len(list_to_encode)))\n",
    "        oh[i] = 1\n",
    "        list_to_one_hot[l] = oh\n",
    "        one_hot_to_item[np.array2string(oh)] = l\n",
    "    return list_to_one_hot, one_hot_to_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Return a list of only the JPG files for a given dir\n",
    "#\n",
    "def list_files(data_dir):\n",
    "    jpg_files = [f for f in listdir(data_dir) if isfile(join(data_dir, f)) and re.search('\\.jpg$',f,flags=re.IGNORECASE)]\n",
    "    return jpg_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load a given list of fruits from the selected data set location\n",
    "#\n",
    "def load_data(fruits_to_get, \n",
    "              test_data_dir,\n",
    "              train_data_dir\n",
    "             ):\n",
    "    \n",
    "    one_hot_dict, item_dict = create_one_hot_encoding_dicts(fruits_to_get)\n",
    "        \n",
    "    test_data = []\n",
    "    train_data = []\n",
    "    \n",
    "    for fruit in fruits_to_get:\n",
    "        \n",
    "        test_fruit_dir = test_data_dir + \"/\" + fruit\n",
    "        train_fruit_dir = train_data_dir + \"/\" + fruit\n",
    "        \n",
    "        if isdir(test_fruit_dir) and isdir(train_fruit_dir):\n",
    "            one_hot_val = one_hot_dict[fruit]\n",
    "            \n",
    "            print(\"loading [\" + fruit + \"]\" + \" one hot: \" + str(one_hot_val))\n",
    "            \n",
    "            print('Test Data')\n",
    "            for img_file in list_files(test_fruit_dir):\n",
    "                test_data.append([np.array(Image.open(join(test_fruit_dir,img_file))), one_hot_val])\n",
    "                print('.', end='')\n",
    "            print('')\n",
    "\n",
    "            print('Training Data')\n",
    "            for img_file in list_files(train_fruit_dir):\n",
    "                train_data.append([np.array(Image.open(join(train_fruit_dir,img_file))), one_hot_val])\n",
    "                print('.', end='')\n",
    "            print('')\n",
    "\n",
    "            img_shape = test_data[0][0].shape\n",
    "            one_hot_shape = test_data[0][1].shape\n",
    "            \n",
    "            # Convert data to numpy\n",
    "            x_test = np.zeros((len(test_data), *img_shape))\n",
    "            y_test = np.zeros((len(test_data), one_hot_shape[0]))\n",
    "            x_train = np.zeros((len(train_data), *img_shape))\n",
    "            y_train = np.zeros((len(train_data), one_hot_shape[0]))\n",
    "            \n",
    "            i = 0 \n",
    "            rnd_idx = random.sample(range(0, len(test_data)), len(test_data))\n",
    "            for img, one_hot in test_data:\n",
    "                x_test[rnd_idx[i]] = img / 255.0  # rescale 0.0 to 1.0\n",
    "                y_test[rnd_idx[i]] = one_hot\n",
    "                i += 1\n",
    "\n",
    "            i = 0 \n",
    "            rnd_idx = random.sample(range(0, len(train_data)), len(train_data))\n",
    "            for img, one_hot in train_data:\n",
    "                x_train[rnd_idx[i]] = img / 255.0  # rescale 0.0 to 1.0\n",
    "                y_train[rnd_idx[i]] = one_hot\n",
    "                i += 1\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"Cannot load unknown fruit - missing from test and/or train data set[\" + fruit + \"]\")\n",
    "            \n",
    "    return x_train, \\\n",
    "           y_train, \\\n",
    "           x_test, \\\n",
    "           y_test, \\\n",
    "           one_hot_dict, \\\n",
    "           item_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_get = [\"Apple Golden 1\",\n",
    "               \"Apple Golden 2\",\n",
    "               \"Apple Golden 3\",\n",
    "               \"Apple Red 1\",\n",
    "               \"Apple Red 2\",\n",
    "               \"Apple Red 3\"]              \n",
    "x_train, y_train, x_test, y_test, _, item_dict = load_data(list_to_get, TEST_DATA, TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_train[i], interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Conv2D, Flatten, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import multi_gpu_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_layers(model_name,\n",
    "                     input_shape):\n",
    "    cnn_in = Input(shape=input_shape, name = \"cnn0Input\")\n",
    "    cnn_l1 = Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', name = \"cnn1_Conv2d\")(cnn_in) \n",
    "    cnn_l2 = MaxPooling2D(pool_size=(2, 2), name = \"cnn2_MaxPool2D\")(cnn_l1)\n",
    "    cnn_l3 = BatchNormalization(name = \"cnn3_BatchNorm\")(cnn_l2) \n",
    "    cnn_l4 = Conv2D(32, kernel_size=(3, 3), strides=(2, 2), activation='relu', name = \"cnn3_conv2d\")(cnn_l3)\n",
    "    cnn_l5 = MaxPooling2D(pool_size=(2, 2), name = \"cnn5_MaxPool2D\")(cnn_l4)\n",
    "    cnn_l6 = BatchNormalization(name = \"cnn6_BatchNorm\")(cnn_l5) \n",
    "    cnn_l7 = Dropout(rate=0.25,name = \"cnn7_Dropout\")(cnn_l6) \n",
    "    cnn_out = Flatten(name = \"cnnOutput_Flatten\")(cnn_l7)\n",
    "    return cnn_in, cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_layers(model_name,\n",
    "                     input_shape):\n",
    "    cnn_in = Input(shape=input_shape, name = \"cnn0Input\")\n",
    "    cnn_l1 = Conv2D(4, kernel_size=(5, 5), strides=(2, 2), activation='relu', name = \"cnn1_Conv2d\")(cnn_in) \n",
    "    cnn_l2 = MaxPooling2D(pool_size=(2, 2), name = \"cnn2_MaxPool2D\")(cnn_l1)\n",
    "    cnn_l3 = BatchNormalization(name = \"cnn3_BatchNorm\")(cnn_l2) \n",
    "    cnn_l7 = Dropout(rate=0.25,name = \"cnn7_Dropout\")(cnn_l3) \n",
    "    cnn_out = Flatten(name = \"cnnOutput_Flatten\")(cnn_l7)\n",
    "    return cnn_in, cnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_layers(model_name,\n",
    "                            num_classes,\n",
    "                            input_layer):\n",
    "    cl_l1 = Dense(25, activation='relu', name = \"clInput_Dense\")(input_layer) # 500 -> 50\n",
    "    cl_l2 = Dropout(rate=0.25, name = \"cl1_Dropout\")(cl_l1)\n",
    "    cl_out = Dense(num_classes, activation='softmax', name = \"clOutput\")(cl_l2)\n",
    "    return cl_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name,\n",
    "                input_shape,\n",
    "                num_classes):\n",
    "    model_cnn_in, model_cnn_out = build_cnn_layers(model_name, input_shape)\n",
    "    model_cl_out = build_classifier_layers(model_name, num_classes, model_cnn_out)\n",
    "\n",
    "    model = Model(inputs=[model_cnn_in],outputs=[model_cl_out])\n",
    "    model.name = model_name\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (100, 100, 3)\n",
    "num_classes = 6\n",
    "model_name = \"classifier_\" + str(num_classes)\n",
    "\n",
    "model = create_model(model_name, input_shape, num_classes)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_compile(model):\n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "    model.compile(loss=categorical_crossentropy,\n",
    "                  optimizer=SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=num_epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, y_test)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    color_r = 'tab:red'\n",
    "    color_b = 'tab:blue'\n",
    "\n",
    "    fig, _ = plt.subplots(figsize=(15,6))\n",
    "    \n",
    "    # Loss\n",
    "    ax1 = plt.subplot(1,2,1)\n",
    "    plt.title('Loss')\n",
    "    ax1.set_xlabel('Epoc')\n",
    "    ax1.set_ylabel('Traing Loss', color=color_r)\n",
    "    ax1.plot(epocs, history.history['loss'], color=color_r)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax2 = ax1.twinx()  # 2nd Axis for Validation Loss\n",
    "    ax2.set_ylabel('Validation Loss', color=color_b)  \n",
    "    ax2.plot(epocs, history.history['val_loss'], color=color_b)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    # Accuracy\n",
    "    ax1 = plt.subplot(1,2,2)\n",
    "    plt.title('Accuracy')\n",
    "    ax1.set_xlabel('Epoc')\n",
    "    ax1.set_ylabel('Traing accuracy', color=color_r)\n",
    "    ax1.plot(epocs, history.history['acc'], color=color_r)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax2 = ax1.twinx()  # 2nd Axis for Validation Loss\n",
    "    ax2.set_ylabel('Validation Accuracy', color=color_b)  \n",
    "    ax2.plot(epocs, history.history['val_acc'], color=color_b)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_prediction(model,\n",
    "                          x_test_set, \n",
    "                          y_test_set,\n",
    "                          num_to_test,\n",
    "                          summary = True):\n",
    "    num_passed = 0\n",
    "    list_to_test = np.random.randint(len(x_test_set), size=num_to_test)\n",
    "\n",
    "    for i in list_to_test:\n",
    "        xt = x_test_set[i]\n",
    "        xt = np.reshape(xt,(1,100,100,3))\n",
    "        pred = model.predict(xt)\n",
    "        if(np.argmax(pred) == np.argmax(y_test_set[i])):\n",
    "            if not summary:\n",
    "                print(\"Correct Prediction for x_test element: \" + str(i)) \n",
    "            num_passed += 1\n",
    "        else:\n",
    "            if not summary:\n",
    "                print(\"Failed Prediction for x_test element: \" + str(i))\n",
    "    print(\"\\nOverall Score : \"+ str(round(num_passed/num_to_test,1)*100)+\"%\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model, x_test, y_test, 9, summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_to_get = [\"Apple Braeburn\"]              \n",
    "x1_train, y1_train, x1_test, y1_test, _, item_dict = load_data(list_to_get, TEST_DATA, TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model, x1_test, y1_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w in enumerate(cnn_weights):\n",
    "    print(str(i) + ' : ' + str(w.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_layers(model):\n",
    "    try:\n",
    "        layers = model.get_layer(model_name).layers\n",
    "    except:\n",
    "        layers = model.layers\n",
    "        \n",
    "    return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model strcuture changes when complied for GPU, so we need to look in diffent places for the 'actual' layers\n",
    "def aij_model_summary(model):\n",
    "    \n",
    "    for l in model_layers(model):\n",
    "        print(l.name+\":: params #\"+str(l.count_params()))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aij_model_summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Articles of Interest\n",
    "\n",
    "[gpu article 1](https://datascience.stackexchange.com/questions/23895/multi-gpu-in-keras)\n",
    "[Keras Conv2D](https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model strcuture changes when complied for GPU, so we need to look in diffent places for the 'actual' layers\n",
    "cnn_only = \".*cnn.*\"\n",
    "def aij_save_cnn_layers(model,\n",
    "                        pattern=\".*\"):\n",
    "\n",
    "    for l in model_layers(model):\n",
    "        l_name = l.name\n",
    "        if re.search(pattern, l_name):\n",
    "            w = l.get_weights()\n",
    "            print('Saving Layer :'+ l.name + \":: params #\"+str(l.count_params()))\n",
    "            np.save(l_name + '.npy', w, allow_pickle=True)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aij_save_cnn_layers(model, pattern= \".*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model strcuture changes when complied for GPU, so we need to look in diffent places for the 'actual' layers\n",
    "def aij_load_cnn_layers(model,\n",
    "                        pattern = \".*\",\n",
    "                        trainable = True):\n",
    "    \n",
    "    for l in model_layers(model):\n",
    "        try:\n",
    "            if re.search(pattern, l.name):\n",
    "                w = np.load(l.name+'.npy',allow_pickle=True)\n",
    "                l.set_weights(w)\n",
    "                l.trainable = trainable\n",
    "                print(\"Loaded weights for Layer: \" + l.name + 'Trainable: ' + str(trainable))\n",
    "            else:\n",
    "                print(\"Ignored Layer:\" + l.name + \" as it does not match load pattern\")\n",
    "        except IOError as e:\n",
    "            print(\"No loadable weights for Layer: \"+l.name) \n",
    "        except:\n",
    "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test we can create a new 6 classifer model and re load\n",
    "input_shape = (100, 100, 3)\n",
    "num_classes = 6\n",
    "model_name = \"classifier_reload_test\" + str(num_classes)\n",
    "\n",
    "model_reload_test = create_model(model_name, input_shape, num_classes)\n",
    "model_reload_test = model_compile(model_reload_test)\n",
    "aij_model_summary(model_reload_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model_reload_test, x_test, y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aij_load_cnn_layers(model_reload_test)\n",
    "model = model_compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model_reload_test, x_test, y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (100, 100, 3)\n",
    "num_classes = 7\n",
    "model_name = \"classifier_\" + str(num_classes)\n",
    "\n",
    "model_7_classes = create_model(model_name, input_shape, num_classes)\n",
    "\n",
    "print(model_7_classes.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to recompile model after load\n",
    "aij_load_cnn_layers(model_7_classes, pattern = \"cnn.*\", trainable = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_classes = model_compile(model_7_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_transform_6_to_7_class(y_6c):\n",
    "    sh = y_6c.shape\n",
    "    y_7c = np.zeros((sh[0], sh[1]+1))\n",
    "    y_7c[:,:-1] = y_6c\n",
    "    return y_7c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_7c = one_hot_transform_6_to_7_class(y_train)\n",
    "y_test_7c = one_hot_transform_6_to_7_class(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model_7_classes, x_test, y_test_7c, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "history = model_7_classes.fit(x_train, y_train_7c,\n",
    "                              epochs=num_epochs,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              validation_data=(x_test, y_test_7c)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model_7_classes, x_test, y_test_7c, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epocs = np.arange(0,num_epochs,1)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "plt.title('Loss')\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('Epoc')\n",
    "ax1.set_ylabel('Traing Loss', color=color)\n",
    "ax1.plot(epocs, history.history['loss'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Validation Loss', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(epocs, history.history['val_loss'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_single_class_to_7_class(y_1c):\n",
    "    sh = y_1c.shape\n",
    "    y_7c = np.zeros((sh[0], sh[1]+6))\n",
    "    y_7c[:,6] = y_1c.reshape((sh[0]))\n",
    "    return y_7c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_test_7c = one_hot_single_class_to_7_class(y1_test)\n",
    "y1_train_7c = one_hot_single_class_to_7_class(y1_train)\n",
    "print(y1_test_7c.shape)\n",
    "print(y1_test_7c[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model_7_classes, x1_test, y1_test_7c, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_train = np.concatenate((x_train, x1_train), axis=0)\n",
    "x_all_test = np.concatenate((x_test, x1_test), axis=0)\n",
    "y_all_train = np.concatenate((y_train_7c, y1_train_7c), axis=0)\n",
    "y_all_test = np.concatenate((y_test_7c, y1_test_7c), axis=0)\n",
    "print(x_all_train.shape)\n",
    "print(x_all_test.shape)\n",
    "print(y_all_train.shape)\n",
    "print(y_all_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "history = model_7_classes.fit(x_all_train, y_all_train,\n",
    "                              epochs=num_epochs,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              validation_data=(x_all_test, y_all_test)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model_7_classes, x_test, y_test_7c, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_prediction(model_7_classes, x1_test, y1_test_7c, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
